{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 4 homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This homework has 7 questions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import (RandomForestClassifier)\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    ConfusionMatrixDisplay,\n",
    "    mean_squared_error,\n",
    "    precision_score,\n",
    "    recall_score\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    KFold,\n",
    "    train_test_split\n",
    ")\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Homework, we take another look at the Bank Marketing dataset that we have already examined in Module 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 (1 points)\n",
    "\n",
    "Load the `bank_data.csv` dataset in a variable named `bank_data`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_data = pd.read_csv('data/bank_data.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like we did in Module 1, we remove some variables that would be hard to handle when using our models in a predictive fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    bank_data.drop(['day', 'month', 'duration', 'pdays', 'poutcome'], axis=1, inplace=True)\n",
    "except NameError:\n",
    "    print('The object `bank_data` does not exist! Did you forget to create it?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we encode the response variable (whether or not a customer subscribed a term deposit with the bank following a marketing campaign) with a binary indicator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    bank_data[\"y\"] = bank_data['y'].apply(lambda y: 1 if y == 'yes' else 0)\n",
    "    bank_data.head()\n",
    "except NameError:\n",
    "    print('The object `bank_data` does not exist! Did you forget to create it?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 (1 points)\n",
    "\n",
    "Create \"dummy\" variables for the categorical predictors in the dataset (also known as \"one-hot encoding\").\n",
    "\n",
    "Reassign the new dataframe to the variable `bank_data`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_data = pd.get_dummies(bank_data, dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now separate the predictors from the response variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    X = bank_data.drop('y', axis=1)\n",
    "    Y = bank_data['y']\n",
    "except NameError:\n",
    "    print('The object `bank_data` does not exist! Did you forget to create it?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 (1 points)\n",
    "\n",
    "Split the data into a training and test set (`X_train, X_test, Y_train, Y_test`).\n",
    "\n",
    "Use `random_state=42` and `test_size=0.25`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to use the available data to build a predictive model that can assist us in making our next marketing campaign more efficient.\n",
    "\n",
    "\n",
    "Here are some quantities to keep in mind. Our department estimates that:\n",
    "\n",
    "- a marketing contact with a potential customer costs around 10 Euros on average\n",
    "\n",
    "- a successful contact (i.e. the customer subscribes a term deposit) generates on average 100 Euros of profits for the bank (say, present value net the cost of marketing).\n",
    "\n",
    "Accordingly, we estimate that:\n",
    "\n",
    "- the value associated with a true negative prediction from our model is 10 Euros (it saves us the waste of 10 Euros associated with the marketing contact)\n",
    "\n",
    "- the value associated with a false positive prediction from our model is -10 Euros\n",
    "\n",
    "- the value associated with a false negative prediction from our model is -100 Euros\n",
    "\n",
    "- the value associated with a true positive prediction from our model is +100 Euros.\n",
    "\n",
    "Let's encode this information in a \"value function\" that we will use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_function(y_true, y_pred, tn_value=10, fp_value=-10, fn_value=-100, tp_value=100):\n",
    "    sum_ = y_pred + y_true\n",
    "    diff_ = y_pred - y_true\n",
    "    tn_contrib = tn_value * np.mean((sum_ == 0) & (diff_ == 0))\n",
    "    fp_contrib = fp_value * np.mean((sum_ == 1) & (diff_ == 1))\n",
    "    fn_contrib = fn_value * np.mean((sum_ == 1) & (diff_ == -1))\n",
    "    tp_contrib = tp_value * np.mean((sum_ == 2) & (diff_ == 0))\n",
    "    return tn_contrib + fp_contrib + fn_contrib + tp_contrib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 (1 points)\n",
    "\n",
    "In this exercise, assume that you have already performed cross-validation for an `AdaBoostClassifier` and found that good values for its parameters are as follows:\n",
    "\n",
    "- `base_estimator=DecisionTreeClassifier(random_state=42, max_depth=5)`\n",
    "\n",
    "- `n_estimators=2000`\n",
    "\n",
    "- `learning_rate=0.80`\n",
    "\n",
    "Fit an `AdaBoostClassifier` on the training data using these parameter values (and `random_state=42`).\n",
    "\n",
    "*Warning: it may take a few minutes to fit this beefy model! Feel free to take a coffee break ;)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashayi\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ada_boost = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5, random_state=42),\n",
    "                               random_state=42, n_estimators=2000, learning_rate=0.80).fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also fit a conventional decision tree for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    tree = DecisionTreeClassifier(random_state=42).fit(X_train, Y_train)\n",
    "except NameError:\n",
    "    print('The objects `X_train, Y_train` do not exist!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5 (1 points)\n",
    "\n",
    "Compute the problem-specific \"value function\" for the `AdaBoostClassifier` and for the `DecisionTreeClassifier`. \n",
    "\n",
    "Which model is performing best with respect to this metric?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value using adaboost: 1.42\n",
      "value using tree: 1.08\n"
     ]
    }
   ],
   "source": [
    "#adaboost:\n",
    "print(\"value using adaboost: \" + round(value_function(Y_test, ada_boost.predict(X_test)), 2).astype(str))\n",
    "print(\"value using tree: \" + round(value_function(Y_test, tree.predict(X_test)), 2).astype(str))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My diagnostic: value using adaboost: 1.42\n",
    "value using tree: 1.08\n",
    "since the value of using adaboost is higher, it performs best with respect to this metric.     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now try to quantify what is the monetary impact of using the `AdaBoostClassifier` as opposed to the `DecisionTreeClassifier` on our marketing campaign.\n",
    "\n",
    "First off, for the evaluation of a given model, we will assume that in our marketing campaign we will only contact customers that are predicted as subscribers by our model.\n",
    "\n",
    "With this in mind, let's create a \"marketing campaign profit function\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def marketing_profits(model, X, Y, fp_value=-10, tp_value=100):\n",
    "    tp_contrib = np.sum((model.predict(X) > 0) & (Y > 0)) * tp_value\n",
    "    fp_contrib = np.sum((model.predict(X) > 0) & (Y < 1)) * fp_value\n",
    "    return tp_contrib + fp_contrib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6 (2 points)\n",
    "\n",
    "Based on the test data, by how much (percent-wise) do the profits for our future marketing campaign will increase (or decrease) if we use the `AdaBoostClassifier` ensemble model as opposed to the conventional `DecisionTreeClassifier`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25900\n",
      "24000\n"
     ]
    }
   ],
   "source": [
    "adaboost_profit = marketing_profits(ada_boost, X_test, Y_test) \n",
    "print(adaboost_profit)\n",
    "tree_profit = marketing_profits(tree, X_test, Y_test) \n",
    "print(tree_profit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My diagnostic: profit using adaboost: 25900\n",
    "profit using tree: 24000\n",
    "since the value of using adaboost is higher, it performs best with respect to this metric.     \n",
    "(25900-24000)/25900=7.33%\n",
    "the profit will increase by 7.33%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7 (3 points)\n",
    "\n",
    "1. Build an additional classifier of your choice for this problem.\n",
    "   Make sure to follow best practices with cross-validation and evaluation on\n",
    "   the test set!\n",
    "\n",
    "2. Evaluate it against the two models above with respect to\n",
    "\n",
    "   - the `value_function` that we defined\n",
    "   \n",
    "   - and increase/decrease in marketing campaign profits.\n",
    "\n",
    "A few notes:\n",
    "\n",
    "- The dataset is imbalanced, with only about 10% of the observations in the training\n",
    "  data representing a positive marketing contact (i.e., $Y=1$).\n",
    "  Is there any way to address this issue when fitting the model?\n",
    "  See e.g., the `class_weight` parameter of `AdaBoostClassifier` or other\n",
    "  classification algorithms. Chances are that setting `class_weight=\"balanced\"`\n",
    "  will improve the results.\n",
    "\n",
    "- You can also try and use AUC (the area under the ROC curve) as a target metric\n",
    "  for optimization. If you would like to experiment with that, try to set\n",
    "  `scoring=\"roc_auc\"` in `GridSearchCV`.\n",
    "\n",
    "- We could try and optimize our models for our `value_function` directly.\n",
    "  This may further improve our results. To do so, simply set\n",
    "  `scoring=value_function_wrapper` in `GridSearchCV`.\n",
    "  Note that `value_function_wrapper` is defined in the next cell and it is\n",
    "  simply a version of our `value_function` that can be used as a scoring\n",
    "  function by `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _value_function(y, y_pred, **kwargs):\n",
    "    return value_function(y, y_pred, **kwargs)\n",
    "\n",
    "\n",
    "value_function_wrapper = make_scorer(_value_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value using random forest: 7.13\n",
      "profit using random forest: 58180\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(class_weight=\"balanced\", random_state=42, max_depth=5, n_estimators=2000).fit(X_train, Y_train)\n",
    "# calculate value\n",
    "print(\"value using random forest: \" + round(value_function(Y_test, random_forest.predict(X_test)), 2).astype(str))\n",
    "print(\"profit using random forest: \" + marketing_profits(random_forest, X_test, Y_test).astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My diagnostic: value using adaboost: 1.42\n",
    "value using tree: 1.08\n",
    "since the value of using adaboost is higher, it performs best with respect to this metric.     value using adaboost: 1.42\n",
    "value using tree: 1.08\n",
    "value using random forest: 7.13\n",
    "since the value of using random boost is highest, it performs best with respect to this metric.    \n",
    "\n",
    "profit using adaboost: 25900\n",
    "profit using tree: 24000\n",
    "random forest profit: 58180\n",
    "the profit for random forest is the highest, it performs best with respect to this metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value using random forest scoring1: 7.13\n",
      "profit using random forest scoring1: 58180\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [2000],\n",
    "    'max_depth': [5],\n",
    "    'random_state': [42],\n",
    "    # Add other parameters as needed\n",
    "}\n",
    "random_forest_new = RandomForestClassifier(class_weight=\"balanced\")\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search1 = GridSearchCV(random_forest_new, param_grid, scoring=\"roc_auc\", cv=5)\n",
    "\n",
    "# Fit the GridSearchCV object to your data\n",
    "random_forest_scoring1 = grid_search1.fit(X_train, Y_train)\n",
    "\n",
    "print(\"value using random forest scoring roc auc: \" + round(value_function(Y_test, random_forest_scoring1.predict(X_test)),2).astype(str))\n",
    "print(\"profit using random forest scoring roc auc: \" + marketing_profits(random_forest_scoring1, X_test, Y_test).astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profit using random forest scoring value_function_wrapper: 58180\n"
     ]
    }
   ],
   "source": [
    "# Create a GridSearchCV object\n",
    "grid_search2 = GridSearchCV(random_forest_new, param_grid, scoring=value_function_wrapper, cv=5)\n",
    "\n",
    "# Fit the GridSearchCV object to your data\n",
    "random_forest_scoring2 = grid_search2.fit(X_train, Y_train)\n",
    "\n",
    "print(\"value using random forest scoring value_function_wrapper: \" + round(value_function(Y_test, random_forest_scoring2.predict(X_test)),2).astype(str))\n",
    "print(\"profit using random forest scoring value_function_wrapper: \" + marketing_profits(random_forest_scoring2, X_test, Y_test).astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "value using adaboost: 1.42\n",
    "value using tree: 1.08\n",
    "value using random forest: 7.13\n",
    "value using random forest scoring roc auc: 7.13\n",
    "value using random forest scoring value_function_wrapper: 7.13\n",
    "since the value of using random forest is highest, it performs best with respect to this metric.    \n",
    "\n",
    "profit using adaboost: 25900\n",
    "profit using tree: 24000\n",
    "random forest profit: 58180\n",
    "profit using random forest scoring roc auc: 58180\n",
    "profit using random forest scoring value_function_wrapper: 58180\n",
    "the profit for random forest is the highest\n",
    "\n",
    "in general, random forest, the different model, has better performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
